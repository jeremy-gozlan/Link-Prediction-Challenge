{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout,Reshape, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                # SETTINGS\n",
    "nb_emb_w2v = 30\n",
    "nb_topics = 24\n",
    "w2vModel = Word2Vec.load(\"Files/word2vec_30.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "                        # FORMAT TRAINING : SEPARATE GRAPH INFORMATION FROM TEXT INFORMATION\n",
    "\n",
    "nlpDataframe2 = pd.read_csv(\"Files/nlpTrain.csv\")\n",
    "\n",
    "Link = nlpDataframe2.pop('Link')\n",
    "CosSimilarityDf = nlpDataframe2[['Cos_similarity']]\n",
    "nlpDataframe2.pop('Cos_similarity')\n",
    "\n",
    "topic_list = []\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"1_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"2_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "    \n",
    "\n",
    "embDf = pd.DataFrame(0.0, index=np.arange(nlpDataframe2.shape[0]), columns= topic_list)\n",
    "\n",
    "\n",
    "for index,row in nlpDataframe2.iterrows():\n",
    "    #print(index)\n",
    "    if (index == 50000):\n",
    "        print (50000)\n",
    "        \n",
    "    idx1 = int(row[\"Node1\"])\n",
    "    idx2 = int(row[\"Node2\"])\n",
    "    \n",
    "    try :\n",
    "        node1_values = w2vModel[str(idx1)]\n",
    "    except KeyError:\n",
    "        node1_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "    \n",
    "    try :\n",
    "        node2_values = w2vModel[str(idx2)]\n",
    "    except KeyError:\n",
    "        node2_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "\n",
    "    for i,(v1,v2) in enumerate(zip(node1_values, node2_values)):\n",
    "        \n",
    "        n1_emb_name = \"1_Emb \"+ str(i)\n",
    "        n2_emb_name = \"2_Emb \"+ str(i)\n",
    "        \n",
    "        embDf.at[index, n1_emb_name] = v1\n",
    "        embDf.at[index, n2_emb_name] = v2\n",
    "\n",
    "pop1 = nlpDataframe2.pop(\"Node1\")\n",
    "pop2 = nlpDataframe2.pop(\"Node2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_Emb 0</th>\n",
       "      <th>1_Emb 1</th>\n",
       "      <th>1_Emb 2</th>\n",
       "      <th>1_Emb 3</th>\n",
       "      <th>1_Emb 4</th>\n",
       "      <th>1_Emb 5</th>\n",
       "      <th>1_Emb 6</th>\n",
       "      <th>1_Emb 7</th>\n",
       "      <th>1_Emb 8</th>\n",
       "      <th>1_Emb 9</th>\n",
       "      <th>...</th>\n",
       "      <th>2_Emb 20</th>\n",
       "      <th>2_Emb 21</th>\n",
       "      <th>2_Emb 22</th>\n",
       "      <th>2_Emb 23</th>\n",
       "      <th>2_Emb 24</th>\n",
       "      <th>2_Emb 25</th>\n",
       "      <th>2_Emb 26</th>\n",
       "      <th>2_Emb 27</th>\n",
       "      <th>2_Emb 28</th>\n",
       "      <th>2_Emb 29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.149851</td>\n",
       "      <td>4.094054</td>\n",
       "      <td>1.980226</td>\n",
       "      <td>1.061261</td>\n",
       "      <td>-1.293822</td>\n",
       "      <td>4.226110</td>\n",
       "      <td>3.173213</td>\n",
       "      <td>1.145736</td>\n",
       "      <td>-0.329324</td>\n",
       "      <td>2.007836</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039129</td>\n",
       "      <td>2.486328</td>\n",
       "      <td>0.716066</td>\n",
       "      <td>5.309447</td>\n",
       "      <td>-1.214457</td>\n",
       "      <td>1.535208</td>\n",
       "      <td>2.385972</td>\n",
       "      <td>-0.819087</td>\n",
       "      <td>0.302707</td>\n",
       "      <td>0.007153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.713437</td>\n",
       "      <td>-0.186107</td>\n",
       "      <td>-0.167109</td>\n",
       "      <td>-0.464693</td>\n",
       "      <td>-0.660424</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.691821</td>\n",
       "      <td>-0.293232</td>\n",
       "      <td>-0.505323</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037106</td>\n",
       "      <td>-0.137260</td>\n",
       "      <td>0.734854</td>\n",
       "      <td>0.102968</td>\n",
       "      <td>-0.583279</td>\n",
       "      <td>-0.253284</td>\n",
       "      <td>0.052709</td>\n",
       "      <td>0.452585</td>\n",
       "      <td>0.320666</td>\n",
       "      <td>0.045048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.036839</td>\n",
       "      <td>3.259414</td>\n",
       "      <td>-0.206073</td>\n",
       "      <td>0.603257</td>\n",
       "      <td>-0.867595</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>-0.859987</td>\n",
       "      <td>2.220953</td>\n",
       "      <td>2.649518</td>\n",
       "      <td>4.457850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>2.052428</td>\n",
       "      <td>1.316718</td>\n",
       "      <td>2.722214</td>\n",
       "      <td>-0.695560</td>\n",
       "      <td>-0.528354</td>\n",
       "      <td>1.626114</td>\n",
       "      <td>0.471445</td>\n",
       "      <td>-0.419526</td>\n",
       "      <td>1.729401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.191712</td>\n",
       "      <td>4.765485</td>\n",
       "      <td>-2.723879</td>\n",
       "      <td>1.253531</td>\n",
       "      <td>-3.725234</td>\n",
       "      <td>6.303171</td>\n",
       "      <td>-1.767110</td>\n",
       "      <td>2.476411</td>\n",
       "      <td>-4.272335</td>\n",
       "      <td>7.383749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478634</td>\n",
       "      <td>0.101077</td>\n",
       "      <td>0.530740</td>\n",
       "      <td>0.227917</td>\n",
       "      <td>0.236640</td>\n",
       "      <td>-0.128904</td>\n",
       "      <td>-0.102085</td>\n",
       "      <td>-0.254686</td>\n",
       "      <td>0.242145</td>\n",
       "      <td>0.343943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.475622</td>\n",
       "      <td>-2.404068</td>\n",
       "      <td>-1.396102</td>\n",
       "      <td>-0.700633</td>\n",
       "      <td>0.667871</td>\n",
       "      <td>2.030433</td>\n",
       "      <td>-1.196424</td>\n",
       "      <td>-0.880149</td>\n",
       "      <td>-1.205218</td>\n",
       "      <td>-4.978656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.980820</td>\n",
       "      <td>0.019812</td>\n",
       "      <td>-1.226661</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>0.270624</td>\n",
       "      <td>-0.388618</td>\n",
       "      <td>0.103238</td>\n",
       "      <td>-1.320837</td>\n",
       "      <td>-0.078508</td>\n",
       "      <td>-0.743266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1_Emb 0   1_Emb 1   1_Emb 2   1_Emb 3   1_Emb 4   1_Emb 5   1_Emb 6  \\\n",
       "0 -1.149851  4.094054  1.980226  1.061261 -1.293822  4.226110  3.173213   \n",
       "1  0.713437 -0.186107 -0.167109 -0.464693 -0.660424  0.088300  0.691821   \n",
       "2 -2.036839  3.259414 -0.206073  0.603257 -0.867595  0.086645 -0.859987   \n",
       "3 -4.191712  4.765485 -2.723879  1.253531 -3.725234  6.303171 -1.767110   \n",
       "4 -0.475622 -2.404068 -1.396102 -0.700633  0.667871  2.030433 -1.196424   \n",
       "\n",
       "    1_Emb 7   1_Emb 8   1_Emb 9  ...  2_Emb 20  2_Emb 21  2_Emb 22  2_Emb 23  \\\n",
       "0  1.145736 -0.329324  2.007836  ... -0.039129  2.486328  0.716066  5.309447   \n",
       "1 -0.293232 -0.505323  0.071237  ...  0.037106 -0.137260  0.734854  0.102968   \n",
       "2  2.220953  2.649518  4.457850  ... -0.999971  2.052428  1.316718  2.722214   \n",
       "3  2.476411 -4.272335  7.383749  ... -0.478634  0.101077  0.530740  0.227917   \n",
       "4 -0.880149 -1.205218 -4.978656  ... -0.980820  0.019812 -1.226661  0.087983   \n",
       "\n",
       "   2_Emb 24  2_Emb 25  2_Emb 26  2_Emb 27  2_Emb 28  2_Emb 29  \n",
       "0 -1.214457  1.535208  2.385972 -0.819087  0.302707  0.007153  \n",
       "1 -0.583279 -0.253284  0.052709  0.452585  0.320666  0.045048  \n",
       "2 -0.695560 -0.528354  1.626114  0.471445 -0.419526  1.729401  \n",
       "3  0.236640 -0.128904 -0.102085 -0.254686  0.242145  0.343943  \n",
       "4  0.270624 -0.388618  0.103238 -1.320837 -0.078508 -0.743266  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1422 - accuracy: 0.9485\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.1074 - accuracy: 0.9631\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.1012 - accuracy: 0.9660\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 12s 30us/step - loss: 0.1019 - accuracy: 0.9671\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.1051 - accuracy: 0.9684\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 33us/step - loss: 0.1003 - accuracy: 0.9685\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 16s 39us/step - loss: 0.1429 - accuracy: 0.9479\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.1096 - accuracy: 0.9620\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.1027 - accuracy: 0.9651\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 15s 37us/step - loss: 0.1004 - accuracy: 0.9665\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 15s 38us/step - loss: 0.1020 - accuracy: 0.9670\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1034 - accuracy: 0.9677\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 17s 41us/step - loss: 0.1417 - accuracy: 0.9484\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.1083 - accuracy: 0.9625\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.1003 - accuracy: 0.9652\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.0980 - accuracy: 0.9670\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.1007 - accuracy: 0.9674\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1018 - accuracy: 0.9669\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 14s 33us/step - loss: 0.1398 - accuracy: 0.9495\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.1081 - accuracy: 0.96260s - loss: 0.1081 \n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.1021 - accuracy: 0.9657\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.1018 - accuracy: 0.9668\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1015 - accuracy: 0.9682\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 33us/step - loss: 0.0999 - accuracy: 0.9690\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.1395 - accuracy: 0.9494\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 12s 30us/step - loss: 0.1076 - accuracy: 0.9630\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.1007 - accuracy: 0.9662\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 16s 38us/step - loss: 0.1001 - accuracy: 0.9673\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1020 - accuracy: 0.96800s - loss: 0.1020 - accuracy: \n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.0999 - accuracy: 0.9689\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.1376 - accuracy: 0.9504\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.1046 - accuracy: 0.9640\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.0968 - accuracy: 0.9673\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.0940 - accuracy: 0.9685\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.0940 - accuracy: 0.9697\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 15s 38us/step - loss: 0.0958 - accuracy: 0.9698\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.1411 - accuracy: 0.9493\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 11s 26us/step - loss: 0.1057 - accuracy: 0.9637\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 11s 27us/step - loss: 0.0986 - accuracy: 0.9666\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 11s 27us/step - loss: 0.0967 - accuracy: 0.9678\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.1005 - accuracy: 0.9681\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.0999 - accuracy: 0.9684\n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 14s 35us/step - loss: 0.1411 - accuracy: 0.9486\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 14s 33us/step - loss: 0.1082 - accuracy: 0.9629\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 14s 35us/step - loss: 0.1016 - accuracy: 0.9659\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 16s 39us/step - loss: 0.1013 - accuracy: 0.9668\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 13s 32us/step - loss: 0.1028 - accuracy: 0.96740s - loss: 0.1\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 12s 30us/step - loss: 0.1028 - accuracy: 0.9682\n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 12s 29us/step - loss: 0.1450 - accuracy: 0.9469\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 14s 34us/step - loss: 0.1137 - accuracy: 0.9604\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 14s 35us/step - loss: 0.1048 - accuracy: 0.9645\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 12s 30us/step - loss: 0.1025 - accuracy: 0.9663\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 14s 35us/step - loss: 0.1028 - accuracy: 0.9672\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.1019 - accuracy: 0.9687\n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 13s 31us/step - loss: 0.1402 - accuracy: 0.9489\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 11s 27us/step - loss: 0.1065 - accuracy: 0.9630\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 11s 27us/step - loss: 0.0996 - accuracy: 0.9662\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 11s 27us/step - loss: 0.0991 - accuracy: 0.9673\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 11s 27us/step - loss: 0.1014 - accuracy: 0.9676\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 11s 26us/step - loss: 0.1017 - accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "                                    # K FOLD MODEL TRAINING FOR NEURAL NET\n",
    "listModel = []\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "for train_index, test_index in kf.split(embDf):\n",
    "    \n",
    "    X_train, X_test = embDf.loc[train_index], embDf.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu', input_dim = nb_emb_w2v*2))\n",
    "    model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=6, batch_size=32)\n",
    "    listModel.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the index of the best performing net\n",
    "index = 5\n",
    "model = listModel[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "                                           # FORMAT SUBMISSION DATASET\n",
    "\n",
    "    \n",
    "nlpTestDataframe = pd.read_csv('Files/nlpTest.csv')\n",
    "CosSimilarityTestDf = nlpTestDataframe[['Cos_similarity']]\n",
    "nlpTestDataframe.pop('Cos_similarity')\n",
    "\n",
    "topic_list = []\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"1_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"2_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "    \n",
    "\n",
    "embDfTest = pd.DataFrame(0.0, index=np.arange(nlpTestDataframe.shape[0]), columns= topic_list)\n",
    "\n",
    "for index,row in nlpTestDataframe.iterrows():\n",
    "    #print(index)\n",
    "    if (index == 50000):\n",
    "        print (50000)\n",
    "        \n",
    "    idx1 = int(row[\"Node1\"])\n",
    "    idx2 = int(row[\"Node2\"])\n",
    "    \n",
    "    try :\n",
    "        node1_values = w2vModel[str(idx1)]\n",
    "    except KeyError:\n",
    "        node1_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "    \n",
    "    try :\n",
    "        node2_values = w2vModel[str(idx2)]\n",
    "    except KeyError:\n",
    "        node2_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "\n",
    "    for i,(v1,v2) in enumerate(zip(node1_values, node2_values)):\n",
    "        \n",
    "        n1_emb_name = \"1_Emb \"+ str(i)\n",
    "        n2_emb_name = \"2_Emb \"+ str(i)\n",
    "        \n",
    "        embDfTest.at[index, n1_emb_name] = v1\n",
    "        embDfTest.at[index, n2_emb_name] = v2\n",
    "        \n",
    "pop1 = nlpTestDataframe.pop('Node1')\n",
    "pop2 = nlpTestDataframe.pop('Node2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(embDfTest)\n",
    "submissionDf = pd.DataFrame()\n",
    "submissionDf[\"predicted\"] = predictions.transpose()[0]\n",
    "submissionDf.index.name = 'id'\n",
    "file_name = \"Results/predictionsNodeNeural.csv\"\n",
    "submissionDf.to_csv(file_name, encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "[1.2237279  1.14077849 1.07248285 1.01345167 0.96128956 0.91473894\n",
      " 0.87439923 0.8389899  0.80525883 0.77700532 0.75236057 0.72767794\n",
      " 0.70433068 0.6854349  0.66674258 0.64883572 0.63276792 0.61853466\n",
      " 0.60493208 0.59222763 0.57997105 0.56835337 0.55833326 0.54901494\n",
      " 0.53955862 0.53105689 0.5224053  0.51391077 0.50718957 0.4993488\n",
      " 0.49272122 0.48678077 0.47914542 0.47213859 0.46565521 0.46212669\n",
      " 0.45665881 0.45148553 0.44562116 0.44062262 0.43648843 0.4312721\n",
      " 0.42642521 0.42274965 0.41893074 0.41398815 0.41085221 0.40729297\n",
      " 0.40266384 0.39871735 0.39476062 0.39158684 0.38779425 0.38409731\n",
      " 0.38055927 0.37708259 0.37447749 0.37119661 0.36717868 0.36409484\n",
      " 0.36267795 0.359175   0.35798534 0.35526529 0.35149437 0.34867597\n",
      " 0.34671459 0.34452724 0.34224557 0.33902041 0.33683739 0.3342327\n",
      " 0.33161667 0.3291595  0.32671585 0.32454357 0.32234907 0.32060172\n",
      " 0.31935673 0.31670757 0.31468416 0.31293255 0.31097214 0.30927235\n",
      " 0.30710533 0.30465204 0.30244402 0.30077677 0.29928244 0.29753136\n",
      " 0.29559923 0.29297795 0.29163677 0.29049581 0.2881549  0.2871443\n",
      " 0.28568399 0.28459598 0.28310468 0.2818848 ]\n",
      "Accuracy: 0.9501\n",
      "HERE\n",
      "[1.22242842 1.13923423 1.07023084 1.01124785 0.95714251 0.91001255\n",
      " 0.86955311 0.83395895 0.80147407 0.77311776 0.74800745 0.7232855\n",
      " 0.7008452  0.68177634 0.66325491 0.64585493 0.62980105 0.61562396\n",
      " 0.60160374 0.58965595 0.57738111 0.56571295 0.55380723 0.54486823\n",
      " 0.53644068 0.52871819 0.5201337  0.51130833 0.50297596 0.49536186\n",
      " 0.49014301 0.4829973  0.47663809 0.46997389 0.46560481 0.45918169\n",
      " 0.45354163 0.44799626 0.44297402 0.4373501  0.43277122 0.42741069\n",
      " 0.42383923 0.41918261 0.41499566 0.41261324 0.40787318 0.40399252\n",
      " 0.40015886 0.39595052 0.39174612 0.38951837 0.38580704 0.38257917\n",
      " 0.37909528 0.37587966 0.3731267  0.37073078 0.36900854 0.36606626\n",
      " 0.36226453 0.3594278  0.35677988 0.353374   0.35050347 0.34880965\n",
      " 0.34617224 0.34468633 0.34172009 0.33883969 0.33629471 0.33514835\n",
      " 0.33304462 0.33079536 0.32830184 0.32589667 0.32449533 0.32178094\n",
      " 0.31995722 0.31812883 0.31600506 0.313798   0.31169267 0.30957288\n",
      " 0.30760935 0.30550765 0.30292108 0.30126736 0.29968562 0.29817218\n",
      " 0.29630736 0.29506935 0.29280308 0.29082194 0.2893037  0.28801344\n",
      " 0.28673834 0.28517899 0.28372392 0.28202124]\n",
      "Accuracy: 0.9503\n",
      "HERE\n",
      "[1.22250308 1.13921714 1.07039623 1.01098042 0.95848501 0.91238969\n",
      " 0.87117171 0.83580364 0.80345113 0.77492184 0.74962117 0.72475288\n",
      " 0.70181789 0.68247331 0.6647849  0.64749833 0.63169164 0.61563778\n",
      " 0.60226011 0.58805614 0.5774151  0.56656723 0.55612451 0.54616123\n",
      " 0.53656945 0.52599447 0.51676246 0.50901972 0.50105334 0.49350359\n",
      " 0.48754757 0.48014375 0.47262686 0.465655   0.45892508 0.45369969\n",
      " 0.44772258 0.44333149 0.4390622  0.43456544 0.42995913 0.4256431\n",
      " 0.42058053 0.41778538 0.41345424 0.40881912 0.40439579 0.40011331\n",
      " 0.39660951 0.39305286 0.3887126  0.38613103 0.38301176 0.38059816\n",
      " 0.37720353 0.37399949 0.37018641 0.36902015 0.36611304 0.3624848\n",
      " 0.35963715 0.35762706 0.35481233 0.35256291 0.35013039 0.3484116\n",
      " 0.34628471 0.3436808  0.34121133 0.33853167 0.33618363 0.3345252\n",
      " 0.33242955 0.32910418 0.32628326 0.32515607 0.32312439 0.3212257\n",
      " 0.31946263 0.3170402  0.31405264 0.3122713  0.31050951 0.30938525\n",
      " 0.30737573 0.30692567 0.30491837 0.30301568 0.30176809 0.300461\n",
      " 0.29904412 0.29701439 0.2956328  0.29387265 0.29188432 0.29045678\n",
      " 0.28839928 0.28742155 0.28636455 0.28478859]\n",
      "Accuracy: 0.9500\n",
      "HERE\n",
      "[1.225056   1.14135295 1.07301452 1.01417995 0.96024418 0.91426827\n",
      " 0.8730469  0.83744574 0.80553113 0.77707402 0.74970693 0.72738524\n",
      " 0.70556256 0.684953   0.66699753 0.64965569 0.63400781 0.61852675\n",
      " 0.60635746 0.59329592 0.58128088 0.56951821 0.55931487 0.54945882\n",
      " 0.540068   0.53167395 0.5221641  0.51375488 0.50684747 0.50001085\n",
      " 0.49198644 0.4854617  0.47860715 0.47245065 0.4684858  0.46212806\n",
      " 0.4569853  0.45106278 0.44628047 0.44025044 0.4347861  0.43014248\n",
      " 0.42573624 0.42140161 0.41777774 0.41365557 0.40901492 0.40485107\n",
      " 0.40020579 0.39780285 0.39481717 0.39035316 0.38639029 0.38353182\n",
      " 0.38035762 0.37680979 0.37421502 0.37236315 0.36943701 0.36643895\n",
      " 0.36366441 0.36129518 0.35917221 0.35760227 0.35544067 0.35248549\n",
      " 0.34906515 0.34650322 0.34404785 0.34221803 0.33982592 0.33775489\n",
      " 0.33533193 0.33415584 0.33144104 0.33015463 0.32830619 0.32602882\n",
      " 0.32349136 0.32112567 0.31922384 0.31746506 0.31566274 0.31402653\n",
      " 0.31112816 0.30932785 0.30780618 0.30543619 0.30261597 0.30087136\n",
      " 0.29937199 0.29757656 0.29699611 0.29613849 0.29433794 0.29305982\n",
      " 0.29098871 0.28855296 0.28697295 0.2855379 ]\n",
      "Accuracy: 0.9490\n",
      "HERE\n",
      "[1.22344499 1.13951232 1.07055933 1.01185622 0.95810579 0.91118223\n",
      " 0.87028925 0.83361501 0.80185784 0.77307058 0.7478097  0.72383433\n",
      " 0.70092428 0.68108476 0.66176659 0.64395852 0.62773809 0.61285351\n",
      " 0.59847447 0.58629324 0.57390533 0.56355738 0.55257026 0.54211094\n",
      " 0.53224892 0.52362283 0.51384495 0.50598564 0.49877438 0.4915172\n",
      " 0.48482893 0.47854078 0.47128767 0.46479638 0.4581486  0.45289389\n",
      " 0.44809523 0.4436186  0.43866433 0.433924   0.42948664 0.42406752\n",
      " 0.42069559 0.41592882 0.4116638  0.40818438 0.40447984 0.4015635\n",
      " 0.39825857 0.39435382 0.39030505 0.38660941 0.38307497 0.38001957\n",
      " 0.37698137 0.37407953 0.37111219 0.36866385 0.3661035  0.36377274\n",
      " 0.36089488 0.35805105 0.35571421 0.35305035 0.34986435 0.34795337\n",
      " 0.34520376 0.34224324 0.34004357 0.33723758 0.33603136 0.33423098\n",
      " 0.33155609 0.32917174 0.32732792 0.3250189  0.32309892 0.32096098\n",
      " 0.3186649  0.31676317 0.31455599 0.31274176 0.31137198 0.30827363\n",
      " 0.30650083 0.304962   0.30274126 0.30113616 0.29998302 0.29790412\n",
      " 0.29613773 0.29452031 0.29342433 0.29153038 0.29112087 0.29034657\n",
      " 0.28810201 0.28638429 0.28517098 0.28363241]\n",
      "Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "                                 # K FOLD TRAINING FOR GRADIENT BOOSTING\n",
    "    \n",
    "from sklearn import ensemble\n",
    "    \n",
    "n_estim = 100\n",
    "n_split = 5\n",
    "depth = 5\n",
    "    \n",
    "listModelBoosting = []\n",
    "\n",
    "kf = KFold(n_splits=n_split, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "val_scores = np.zeros((n_estim,), dtype=np.float64)\n",
    "\n",
    "def heldout_score(clf, X_test, y_test):\n",
    "    \"\"\"compute deviance scores on ``X_test`` and ``y_test``. \"\"\"\n",
    "    score = np.zeros((n_estim,), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        score[i] = clf.loss_(y_test, y_pred)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "for train_index, test_index in kf.split(embDf):\n",
    "    \n",
    "    X_train, X_test = embDf.loc[train_index], embDf.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "\n",
    "    clf = ensemble.GradientBoostingClassifier(learning_rate=0.1, n_estimators=n_estim, subsample=1.0,max_depth=depth)\n",
    "    \n",
    "    print('HERE')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_scores += heldout_score(clf, X_test, y_test)\n",
    "    \n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    \n",
    "    listModelBoosting.append(clf)\n",
    "\n",
    "val_scores /= n_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = listModelBoosting[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsBoosting = clf.predict(embDfTest.loc[:])\n",
    "submissionDfBoosting = pd.DataFrame()\n",
    "submissionDfBoosting[\"predicted\"] = predictionsBoosting.transpose()\n",
    "submissionDfBoosting.index.name = 'id'\n",
    "file_name_boosting = \"Results/predictionsNodeBoosting.csv\"\n",
    "submissionDfBoosting.to_csv(file_name_boosting, encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted\n",
       "id           \n",
       "0           1\n",
       "1           1\n",
       "2           0\n",
       "3           0\n",
       "4           1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissionDfBoosting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "Accuracy: 0.8317\n",
      "HERE\n",
      "Accuracy: 0.8335\n",
      "HERE\n",
      "Accuracy: 0.8321\n",
      "HERE\n",
      "Accuracy: 0.8330\n",
      "HERE\n",
      "Accuracy: 0.8338\n"
     ]
    }
   ],
   "source": [
    "                                 # K FOLD TRAINING FOR LOGISTIC REGRESSION\n",
    "    \n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_split = 5\n",
    "C_value = 1.0\n",
    "loss = 'l2'\n",
    "solv = 'lbfgs'\n",
    "\n",
    "listModelLogistic = []\n",
    "\n",
    "kf = KFold(n_splits=n_split, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(embDf):\n",
    "    \n",
    "    X_train, X_test = embDf.loc[train_index], embDf.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "\n",
    "    clf = LogisticRegression(penalty = loss, C = C_value, solver = solv)\n",
    "    \n",
    "    print('HERE')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    \n",
    "    listModelLogistic.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = listModelLogistic[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLogistic = clf.predict(embDfTest.loc[:])\n",
    "submissionDfLogistic = pd.DataFrame()\n",
    "submissionDfLogistic[\"predicted\"] = predictionsLogistic.transpose()\n",
    "submissionDfLogistic.index.name = 'id'\n",
    "file_name_logistic = \"Results/predictionsNodeLogistic.csv\"\n",
    "submissionDfLogistic.to_csv(file_name_logistic, encoding='utf-8', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
