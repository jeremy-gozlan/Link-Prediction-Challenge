{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from node2vec import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout,Reshape, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "from sklearn.model_selection import KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                # SETTINGS\n",
    "nb_emb_w2v = 30\n",
    "nb_topics = 24\n",
    "w2vModel = Word2Vec.load(\"Files/word2vec_30.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "                        # FORMAT TRAINING : SEPARATE GRAPH INFORMATION FROM TEXT INFORMATION\n",
    "\n",
    "nlpDataframe2 = pd.read_csv(\"Files/nlpTrain.csv\")\n",
    "\n",
    "Link = nlpDataframe2.pop('Link')\n",
    "CosSimilarityDf = nlpDataframe2[['Cos_similarity']]\n",
    "nlpDataframe2.pop('Cos_similarity')\n",
    "\n",
    "topic_list = []\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"1_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"2_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "    \n",
    "\n",
    "embDf = pd.DataFrame(0.0, index=np.arange(nlpDataframe2.shape[0]), columns= topic_list)\n",
    "\n",
    "\n",
    "for index,row in nlpDataframe2.iterrows():\n",
    "    #print(index)\n",
    "    if (index == 50000):\n",
    "        print (50000)\n",
    "        \n",
    "    idx1 = int(row[\"Node1\"])\n",
    "    idx2 = int(row[\"Node2\"])\n",
    "    \n",
    "    try :\n",
    "        node1_values = w2vModel[str(idx1)]\n",
    "    except KeyError:\n",
    "        node1_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "    \n",
    "    try :\n",
    "        node2_values = w2vModel[str(idx2)]\n",
    "    except KeyError:\n",
    "        node2_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "\n",
    "    for i,(v1,v2) in enumerate(zip(node1_values, node2_values)):\n",
    "        \n",
    "        n1_emb_name = \"1_Emb \"+ str(i)\n",
    "        n2_emb_name = \"2_Emb \"+ str(i)\n",
    "        \n",
    "        embDf.at[index, n1_emb_name] = v1\n",
    "        embDf.at[index, n2_emb_name] = v2\n",
    "\n",
    "pop1 = nlpDataframe2.pop(\"Node1\")\n",
    "pop2 = nlpDataframe2.pop(\"Node2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_Topic 0</th>\n",
       "      <th>1_Topic 1</th>\n",
       "      <th>1_Topic 2</th>\n",
       "      <th>1_Topic 3</th>\n",
       "      <th>1_Topic 4</th>\n",
       "      <th>1_Topic 5</th>\n",
       "      <th>1_Topic 6</th>\n",
       "      <th>1_Topic 7</th>\n",
       "      <th>1_Topic 8</th>\n",
       "      <th>1_Topic 9</th>\n",
       "      <th>...</th>\n",
       "      <th>2_Topic 14</th>\n",
       "      <th>2_Topic 15</th>\n",
       "      <th>2_Topic 16</th>\n",
       "      <th>2_Topic 17</th>\n",
       "      <th>2_Topic 18</th>\n",
       "      <th>2_Topic 19</th>\n",
       "      <th>2_Topic 20</th>\n",
       "      <th>2_Topic 21</th>\n",
       "      <th>2_Topic 22</th>\n",
       "      <th>2_Topic 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "      <td>0.020837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.865167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_Topic 0  1_Topic 1  1_Topic 2  1_Topic 3  1_Topic 4  1_Topic 5  \\\n",
       "0        0.0        0.0        0.0   0.092979        0.0   0.398997   \n",
       "1        0.0        0.0        0.0   0.000000        0.0   0.000000   \n",
       "2        0.0        0.0        0.0   0.000000        0.0   0.000000   \n",
       "3        0.0        0.0        0.0   0.000000        0.0   0.000000   \n",
       "4        0.0        0.0        0.0   0.000000        0.0   0.000000   \n",
       "\n",
       "   1_Topic 6  1_Topic 7  1_Topic 8  1_Topic 9  ...  2_Topic 14  2_Topic 15  \\\n",
       "0   0.000000        0.0        0.0        0.0  ...    0.020837    0.020837   \n",
       "1   0.000000        0.0        0.0        0.0  ...    0.000000    0.000000   \n",
       "2   0.000000        0.0        0.0        0.0  ...    0.000000    0.000000   \n",
       "3   0.987991        0.0        0.0        0.0  ...    0.000000    0.000000   \n",
       "4   0.000000        0.0        0.0        0.0  ...    0.000000    0.000000   \n",
       "\n",
       "   2_Topic 16  2_Topic 17  2_Topic 18  2_Topic 19  2_Topic 20  2_Topic 21  \\\n",
       "0    0.020837    0.020837    0.020837    0.520757    0.020837    0.020837   \n",
       "1    0.000000    0.959254    0.000000    0.000000    0.000000    0.000000   \n",
       "2    0.000000    0.000000    0.000000    0.000000    0.371359    0.000000   \n",
       "3    0.000000    0.000000    0.134329    0.865167    0.000000    0.000000   \n",
       "4    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "   2_Topic 22  2_Topic 23  \n",
       "0    0.020837    0.020837  \n",
       "1    0.040073    0.000000  \n",
       "2    0.000000    0.000000  \n",
       "3    0.000000    0.000000  \n",
       "4    0.000000    0.000000  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpDataframe2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 23s 55us/step - loss: 0.5433 - accuracy: 0.7199\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 23s 56us/step - loss: 0.5207 - accuracy: 0.7385\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 23s 57us/step - loss: 0.5157 - accuracy: 0.7428\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 25s 61us/step - loss: 0.5128 - accuracy: 0.7455\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 25s 60us/step - loss: 0.5117 - accuracy: 0.7467\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 23s 56us/step - loss: 0.5109 - accuracy: 0.7474\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 23s 56us/step - loss: 0.5432 - accuracy: 0.7199\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 23s 57us/step - loss: 0.5191 - accuracy: 0.7386\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 24s 59us/step - loss: 0.5134 - accuracy: 0.7431\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 24s 59us/step - loss: 0.5103 - accuracy: 0.7468\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 22s 54us/step - loss: 0.5086 - accuracy: 0.7489\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 23s 56us/step - loss: 0.5088 - accuracy: 0.7501\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 23s 57us/step - loss: 0.5422 - accuracy: 0.7208\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 23s 56us/step - loss: 0.5199 - accuracy: 0.7389\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.5166 - accuracy: 0.7425\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.5153 - accuracy: 0.7444\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 12s 30us/step - loss: 0.5138 - accuracy: 0.7462\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.5131 - accuracy: 0.7476\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.5425 - accuracy: 0.7215\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.5200 - accuracy: 0.7390\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 14s 35us/step - loss: 0.5156 - accuracy: 0.7425\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.5133 - accuracy: 0.7446\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 15s 36us/step - loss: 0.5111 - accuracy: 0.7463\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.5099 - accuracy: 0.7476\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 12s 30us/step - loss: 0.5430 - accuracy: 0.72030s - loss: 0.5435 - ac\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5213 - accuracy: 0.7374\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5160 - accuracy: 0.74230s - loss: 0.5160 - accuracy: 0.\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5157 - accuracy: 0.74390s - loss: 0\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5152 - accuracy: 0.7446\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.5120 - accuracy: 0.7470\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 14s 34us/step - loss: 0.5433 - accuracy: 0.7202\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.5207 - accuracy: 0.7392\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.5171 - accuracy: 0.7433\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 13s 32us/step - loss: 0.5163 - accuracy: 0.7455\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 12s 30us/step - loss: 0.5169 - accuracy: 0.7468\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5167 - accuracy: 0.7480\n",
      "Epoch 1/6\n",
      "408417/408417 [==============================] - 11s 28us/step - loss: 0.5430 - accuracy: 0.7196\n",
      "Epoch 2/6\n",
      "408417/408417 [==============================] - 12s 29us/step - loss: 0.5183 - accuracy: 0.7384\n",
      "Epoch 3/6\n",
      "408417/408417 [==============================] - 13s 31us/step - loss: 0.5127 - accuracy: 0.7429\n",
      "Epoch 4/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.5104 - accuracy: 0.7451\n",
      "Epoch 5/6\n",
      "408417/408417 [==============================] - 13s 33us/step - loss: 0.5095 - accuracy: 0.7466\n",
      "Epoch 6/6\n",
      "408417/408417 [==============================] - 11s 28us/step - loss: 0.5101 - accuracy: 0.7469\n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 12s 30us/step - loss: 0.5435 - accuracy: 0.7191\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 12s 30us/step - loss: 0.5210 - accuracy: 0.7368\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 12s 29us/step - loss: 0.5144 - accuracy: 0.7429\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 13s 32us/step - loss: 0.5115 - accuracy: 0.7457\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5106 - accuracy: 0.7472\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 13s 31us/step - loss: 0.5098 - accuracy: 0.7485\n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5417 - accuracy: 0.7214\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 15s 38us/step - loss: 0.5185 - accuracy: 0.7384\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 14s 34us/step - loss: 0.5149 - accuracy: 0.7426\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 14s 34us/step - loss: 0.5145 - accuracy: 0.7445\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5189 - accuracy: 0.7444\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 14s 35us/step - loss: 0.5211 - accuracy: 0.74520s - loss: 0.5212 - \n",
      "Epoch 1/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5420 - accuracy: 0.7215\n",
      "Epoch 2/6\n",
      "408418/408418 [==============================] - 13s 31us/step - loss: 0.5186 - accuracy: 0.7394\n",
      "Epoch 3/6\n",
      "408418/408418 [==============================] - 15s 36us/step - loss: 0.5138 - accuracy: 0.7440\n",
      "Epoch 4/6\n",
      "408418/408418 [==============================] - 15s 36us/step - loss: 0.5130 - accuracy: 0.7458\n",
      "Epoch 5/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5136 - accuracy: 0.7465\n",
      "Epoch 6/6\n",
      "408418/408418 [==============================] - 13s 33us/step - loss: 0.5141 - accuracy: 0.74710s - los\n"
     ]
    }
   ],
   "source": [
    "                                    # K FOLD MODEL TRAINING FOR NEURAL NET\n",
    "listModel = []\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "for train_index, test_index in kf.split(embDf):\n",
    "    \n",
    "    X_train, X_test = nlpDataframe2.loc[train_index], nlpDataframe2.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu', input_dim = nb_topics*2))\n",
    "    model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=6, batch_size=32)\n",
    "    listModel.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the index of the best performing net\n",
    "index = 1\n",
    "model = listModel[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "                                           # FORMAT SUBMISSION DATASET\n",
    "\n",
    "    \n",
    "nlpTestDataframe = pd.read_csv('Files/nlpTest.csv')\n",
    "CosSimilarityTestDf = nlpTestDataframe[['Cos_similarity']]\n",
    "nlpTestDataframe.pop('Cos_similarity')\n",
    "\n",
    "topic_list = []\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"1_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "\n",
    "for i in range(nb_emb_w2v):\n",
    "    topic_name = \"2_Emb \"+ str(i)\n",
    "    topic_list.append(topic_name)\n",
    "    \n",
    "\n",
    "embDfTest = pd.DataFrame(0.0, index=np.arange(nlpTestDataframe.shape[0]), columns= topic_list)\n",
    "\n",
    "for index,row in nlpTestDataframe.iterrows():\n",
    "    #print(index)\n",
    "    if (index == 50000):\n",
    "        print (50000)\n",
    "        \n",
    "    idx1 = int(row[\"Node1\"])\n",
    "    idx2 = int(row[\"Node2\"])\n",
    "    \n",
    "    try :\n",
    "        node1_values = w2vModel[str(idx1)]\n",
    "    except KeyError:\n",
    "        node1_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "    \n",
    "    try :\n",
    "        node2_values = w2vModel[str(idx2)]\n",
    "    except KeyError:\n",
    "        node2_values = [0.0 for i in range(nb_emb_w2v)]\n",
    "\n",
    "    for i,(v1,v2) in enumerate(zip(node1_values, node2_values)):\n",
    "        \n",
    "        n1_emb_name = \"1_Emb \"+ str(i)\n",
    "        n2_emb_name = \"2_Emb \"+ str(i)\n",
    "        \n",
    "        embDfTest.at[index, n1_emb_name] = v1\n",
    "        embDfTest.at[index, n2_emb_name] = v2\n",
    "        \n",
    "pop1 = nlpTestDataframe.pop('Node1')\n",
    "pop2 = nlpTestDataframe.pop('Node2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(nlpTestDataframe)\n",
    "submissionDf = pd.DataFrame()\n",
    "submissionDf[\"predicted\"] = predictions.transpose()[0]\n",
    "submissionDf.index.name = 'id'\n",
    "file_name = \"Results/predictionsTextNeural.csv\"\n",
    "submissionDf.to_csv(file_name, encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "[1.29594696 1.27373839 1.25466698 1.23528288 1.21645553 1.20126694\n",
      " 1.18467281 1.17308    1.16302512 1.15024002 1.14084685 1.13092677\n",
      " 1.12415354 1.1171357  1.11001119 1.1024385  1.09626774 1.09101816\n",
      " 1.08496277 1.0797193  1.07455534 1.07078925 1.06719471 1.06396056\n",
      " 1.06035899 1.05823984 1.0504859  1.04798547 1.04573238 1.04296647\n",
      " 1.04067904 1.03855144 1.03631589 1.03384419 1.02961174 1.02857625\n",
      " 1.02637367 1.02508657 1.02321319 1.01827493 1.01670309 1.01467699\n",
      " 1.01323254 1.01095614 1.00989913 1.00836825 1.00555194 1.00418636\n",
      " 1.0022407  1.00116451 0.99977465 0.99846445 0.99767516 0.99620116\n",
      " 0.99458607 0.99337245 0.99115587 0.98978069 0.98801811 0.9871\n",
      " 0.98515446 0.9839949  0.98327291 0.9819938  0.98123801 0.98029994\n",
      " 0.97789453 0.97581119 0.97523526 0.97463661 0.97292997 0.97092976\n",
      " 0.97035535 0.96959147 0.96845785 0.96750184 0.96593014 0.9653037\n",
      " 0.96418406 0.96333148 0.96269375 0.96089346 0.95941823 0.95770185\n",
      " 0.95629156 0.9555987  0.9549648  0.95426589 0.95278357 0.95152197\n",
      " 0.94956568 0.94825846 0.94650045 0.94565277 0.94422236 0.94250458\n",
      " 0.94218806 0.94095022 0.93974157 0.93934161]\n",
      "Accuracy: 0.7963\n",
      "HERE\n",
      "[1.29535781 1.27287999 1.2542589  1.23526525 1.2182617  1.1997149\n",
      " 1.18717106 1.17551493 1.16212237 1.15350008 1.14117545 1.13280706\n",
      " 1.12346207 1.11638452 1.10839304 1.10266257 1.0976099  1.09097173\n",
      " 1.0866015  1.0809547  1.07438834 1.06981996 1.06596138 1.06360946\n",
      " 1.06142574 1.05792883 1.05533489 1.05148471 1.04647365 1.0428764\n",
      " 1.04028037 1.0385862  1.03670223 1.03403691 1.03119787 1.02868789\n",
      " 1.02705124 1.02547983 1.02247118 1.02070843 1.01969061 1.01870578\n",
      " 1.01577993 1.01477306 1.01292711 1.01189943 1.01085919 1.00966347\n",
      " 1.00885197 1.00512736 1.00301577 1.00109925 1.00011819 0.99689603\n",
      " 0.99448049 0.99361261 0.99248373 0.99117852 0.99060133 0.98976724\n",
      " 0.98847206 0.98782342 0.98671207 0.98582595 0.98400895 0.98206965\n",
      " 0.980127   0.97909396 0.97791659 0.97605908 0.97510878 0.97454765\n",
      " 0.97284336 0.97166063 0.97028884 0.96861085 0.96780587 0.96590483\n",
      " 0.96530055 0.9645169  0.96294906 0.9613639  0.95991253 0.95849612\n",
      " 0.9581291  0.95671238 0.95507061 0.95365529 0.95149175 0.95116408\n",
      " 0.94985532 0.94891713 0.94825407 0.9475765  0.9460401  0.94389275\n",
      " 0.94219905 0.94141977 0.94048858 0.93965493]\n",
      "Accuracy: 0.7960\n",
      "HERE\n",
      "[1.29526996 1.27254703 1.25349035 1.23410158 1.21318646 1.1990749\n",
      " 1.18544735 1.16994113 1.15989959 1.14694622 1.1351824  1.12677226\n",
      " 1.11912454 1.11137728 1.10538371 1.0992941  1.09363815 1.08929361\n",
      " 1.08231898 1.07621934 1.07181508 1.06862322 1.06598665 1.06218908\n",
      " 1.05860088 1.05459775 1.05290315 1.04997411 1.04805468 1.04490534\n",
      " 1.04154998 1.04036417 1.03837715 1.03643265 1.03065562 1.02945709\n",
      " 1.02546872 1.02267806 1.02013042 1.01831993 1.01588917 1.01357756\n",
      " 1.01225128 1.0100841  1.0088117  1.00705227 1.00441257 1.00272694\n",
      " 1.00140841 1.00071106 0.99985871 0.99825457 0.99729652 0.99388306\n",
      " 0.99285351 0.99175726 0.98943904 0.98827    0.98656165 0.98459798\n",
      " 0.9839066  0.98249247 0.98208193 0.98158478 0.97940045 0.97792084\n",
      " 0.97690568 0.97629627 0.97443891 0.97289373 0.97173082 0.97120938\n",
      " 0.97020829 0.96900029 0.96707544 0.9655362  0.96471727 0.96396229\n",
      " 0.96320964 0.96193066 0.96074544 0.95815653 0.95669488 0.95573685\n",
      " 0.95528055 0.95349276 0.95227383 0.9507727  0.94846564 0.94705485\n",
      " 0.94623828 0.94451808 0.94284369 0.9417794  0.94154405 0.9396289\n",
      " 0.93872946 0.93762917 0.93670853 0.93580935]\n",
      "Accuracy: 0.7969\n",
      "HERE\n",
      "[1.29768462 1.2756676  1.25645568 1.23802436 1.22053835 1.20137646\n",
      " 1.1892975  1.17722207 1.16648739 1.15248979 1.14336788 1.1315879\n",
      " 1.1231716  1.11602307 1.10970619 1.1021758  1.09526222 1.08825087\n",
      " 1.08256567 1.07694605 1.07287101 1.06901284 1.06443951 1.06089361\n",
      " 1.05837724 1.05623096 1.05344096 1.05156974 1.04803186 1.04579299\n",
      " 1.04287751 1.03891286 1.03751375 1.03502183 1.03150836 1.02885082\n",
      " 1.02619321 1.0213329  1.01917745 1.01781275 1.01671039 1.01462844\n",
      " 1.01292783 1.01056246 1.00949897 1.00859381 1.00732498 1.00492862\n",
      " 1.00257029 1.0019912  1.00083834 0.99955801 0.99872072 0.99645763\n",
      " 0.99468911 0.99243559 0.98962176 0.98872513 0.98790741 0.98592833\n",
      " 0.98527448 0.98433893 0.98296878 0.98257843 0.98099025 0.97910854\n",
      " 0.97771094 0.97567755 0.97500253 0.97324028 0.97199289 0.9714511\n",
      " 0.96988841 0.96939181 0.96482141 0.96393987 0.96314295 0.96157666\n",
      " 0.96003074 0.95901299 0.95869068 0.95762378 0.95618108 0.95419523\n",
      " 0.95242807 0.95143561 0.95050959 0.94946559 0.94854319 0.94818029\n",
      " 0.94755894 0.94687934 0.94620818 0.94494907 0.94384048 0.94245575\n",
      " 0.94143233 0.94060709 0.93950284 0.93834352]\n",
      "Accuracy: 0.7979\n",
      "HERE\n",
      "[1.29690707 1.27413178 1.25469011 1.23580181 1.21472383 1.19971566\n",
      " 1.18719428 1.17241649 1.16126355 1.15209649 1.14009735 1.13135717\n",
      " 1.12204127 1.11420221 1.10788164 1.10105667 1.09623604 1.08997125\n",
      " 1.08365219 1.07836845 1.07412181 1.06957034 1.06494328 1.06093086\n",
      " 1.05652478 1.05313536 1.04892134 1.04722974 1.04521138 1.04235232\n",
      " 1.04080489 1.03936825 1.03208571 1.02800538 1.0248521  1.02207052\n",
      " 1.02123682 1.02018146 1.01799579 1.01570179 1.01299079 1.01219401\n",
      " 1.01119371 1.00934876 1.00745766 1.0053755  1.00417263 1.00266592\n",
      " 0.99991736 0.99814392 0.99737293 0.99515688 0.99446013 0.99288513\n",
      " 0.99182351 0.99049698 0.98888138 0.9866907  0.98597171 0.98322013\n",
      " 0.98156666 0.98101944 0.97994526 0.97930615 0.97828248 0.97596222\n",
      " 0.97437136 0.97286456 0.9712313  0.96854173 0.96794282 0.96635239\n",
      " 0.9657024  0.9639863  0.9626952  0.96180989 0.95935828 0.95838058\n",
      " 0.95657537 0.95596778 0.95475822 0.95437797 0.95295489 0.95219456\n",
      " 0.95045762 0.94918679 0.94843555 0.94606744 0.94536227 0.94478976\n",
      " 0.94395041 0.94317413 0.94177937 0.94088683 0.94032058 0.93851493\n",
      " 0.93790248 0.93746182 0.93696968 0.93494162]\n",
      "Accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "                                 # K FOLD TRAINING FOR GRADIENT BOOSTING\n",
    "    \n",
    "from sklearn import ensemble\n",
    "    \n",
    "n_estim = 100\n",
    "n_split = 5\n",
    "depth = 7\n",
    "\n",
    "    \n",
    "listModelBoosting = []\n",
    "\n",
    "kf = KFold(n_splits=n_split, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "val_scores = np.zeros((n_estim,), dtype=np.float64)\n",
    "\n",
    "def heldout_score(clf, X_test, y_test):\n",
    "    \"\"\"compute deviance scores on ``X_test`` and ``y_test``. \"\"\"\n",
    "    score = np.zeros((n_estim,), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(clf.staged_decision_function(X_test)):\n",
    "        score[i] = clf.loss_(y_test, y_pred)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "for train_index, test_index in kf.split(embDf):\n",
    "    \n",
    "    X_train, X_test = nlpDataframe2.loc[train_index], nlpDataframe2.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "\n",
    "    clf = ensemble.GradientBoostingClassifier(learning_rate=0.1, n_estimators=n_estim, subsample=1.0,max_depth=depth)\n",
    "    \n",
    "    print('HERE')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_scores += heldout_score(clf, X_test, y_test)\n",
    "    \n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    \n",
    "    listModelBoosting.append(clf)\n",
    "\n",
    "val_scores /= n_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = listModelBoosting[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsBoosting = clf.predict(nlpTestDataframe)\n",
    "submissionDfBoosting = pd.DataFrame()\n",
    "submissionDfBoosting[\"predicted\"] = predictionsBoosting.transpose()\n",
    "submissionDfBoosting.index.name = 'id'\n",
    "file_name_boosting = \"Results/predictionsTextBoosting.csv\"\n",
    "submissionDfBoosting.to_csv(file_name_boosting, encoding='utf-8', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "Accuracy: 0.6345\n",
      "HERE\n",
      "Accuracy: 0.6356\n",
      "HERE\n",
      "Accuracy: 0.6366\n",
      "HERE\n",
      "Accuracy: 0.6344\n",
      "HERE\n",
      "Accuracy: 0.6342\n"
     ]
    }
   ],
   "source": [
    "                                 # K FOLD TRAINING FOR LOGISTIC REGRESSION\n",
    "    \n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_split = 5\n",
    "C_value = 1.0\n",
    "loss = 'l2'\n",
    "solv = 'lbfgs'\n",
    "max_iter_value=200\n",
    "\n",
    "listModelLogistic = []\n",
    "\n",
    "kf = KFold(n_splits=n_split, random_state=42, shuffle=True)# Define the split - into 10 folds \n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(nlpDataframe2):\n",
    "    \n",
    "    X_train, X_test = nlpDataframe2.loc[train_index], nlpDataframe2.loc[test_index]\n",
    "    y_train, y_test = Link[train_index], Link[test_index]\n",
    "\n",
    "    clf = LogisticRegression(penalty = loss, C = C_value, solver = solv, max_iter = max_iter_value)\n",
    "    \n",
    "    print('HERE')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Accuracy: {:.4f}\".format(acc))\n",
    "    \n",
    "    listModelLogistic.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = listModelLogistic[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLogistic = clf.predict(nlpTestDataframe)\n",
    "submissionDfLogistic = pd.DataFrame()\n",
    "submissionDfLogistic[\"predicted\"] = predictionsLogistic.transpose()\n",
    "submissionDfLogistic.index.name = 'id'\n",
    "file_name_logistic = \"Results/predictionsTextLogistic.csv\"\n",
    "submissionDfLogistic.to_csv(file_name_logistic, encoding='utf-8', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
